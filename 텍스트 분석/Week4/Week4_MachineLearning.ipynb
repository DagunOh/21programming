{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `머신러닝(기계학습) `\n",
    "\n",
    "- 데이터를 구문 분석하고 해당 데이터를 통해 학습한 후 정보를 바탕으로 결정을 내리기 위해 학습한 내용을 적용하는 알고리즘\n",
    "\n",
    "\n",
    "- 주어진 데이터로 기능을 수행하고, 시간이 지남에 따라 그 기능이 점차 향상됨. \n",
    "\n",
    "\n",
    "- `데이터를 학습시키고, 결과를 예측.`\n",
    "\n",
    "\n",
    "- `지도학습`과 `비지도학습`으로 나뉨\n",
    "\n",
    "----\n",
    "\n",
    "### 1. 머신러닝의 분류\n",
    "### 1) 지도 학습\n",
    "---\n",
    "* 답이 제공되어 나중에 답을 맞출 수 있게 하는 족보같은 개념.    \n",
    "    \n",
    "    * 지도학습은 결국 `답을 찾기 위해 활용하는 알고리즘`. \n",
    "        \n",
    "    * 답이 있는 **`훈련 데이터 (Train Set)`** 를 이용해 학습시킴\n",
    "        \n",
    "    * 그 다음, 우리가 예측하고자 하는 데이터를 평가 데이터, **`테스트 데이터(Test Data)`** 라 하고, 얼마나 정확하게 답을 맞추었느냐에 따라 알고리즘의 성능을 결정.  \n",
    "    \n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "> ### 분류\n",
    ">> #### 1. 범주형 데이터\n",
    ">> 데이터의 값이 숫자가 아닌, A,B,C 등으로 구분되는 데이터. \n",
    "\n",
    "> ### 회귀\n",
    "> `일반적인 관계 특성.` \n",
    ">> #### 2. 연속형 데이터 \n",
    ">> 값들이 어느 범위 내에서 `수치형태`로 존재하는 데이터. \n",
    "    \n",
    " \n",
    "\n",
    "### 2) 비지도 학습\n",
    "---\n",
    "* 답이 제공되지 않은 데이터를 학습시키는 것\n",
    "    * 결국 최종 판단은 사람의 몫\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*!! 어차피 우리는 지도학습만 배울겁니다!!*\n",
    "---\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "### 2. 사이킷런 이용\n",
    "---\n",
    "#### <span style=\"color:blue\"> 1.필요한 모듈들 import</span>\n",
    "\n",
    "~~~python\n",
    "\n",
    "    import numpy as np                                       ## 기초 수학 연산 및 행렬계산\n",
    "    import pandas as pd                                      ## 데이터프레임 사용\n",
    "\n",
    "    from sklearn.model_selection import train_test_split     ## train, test 데이터 분할\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression        ## 선형 회귀분석\n",
    "    from sklearn.linear_model import LogisticRegression      ## 로지스틱 회귀분석\n",
    "    from sklearn import svm                                  ## 서포트 벡터 머신\n",
    "    from sklearn import tree                                 ## 의사결정나무\n",
    "    from sklearn.ensemble import RandomForestClassifier      ## 랜덤포레스트\n",
    "\n",
    "    import matplotlib.pyplot as plt                          ## plot 그릴때 사용\n",
    "    \n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "#### <span style=\"color:blue\"> 2.데이터 전처리 </span>\n",
    "\n",
    "\n",
    "- 텍스트든, 일반 수치형 데이터든 상관없습니다.\n",
    "- 전처리 과정이 생각보다 몹시 중요합니다.\n",
    "- 학습에 도움이 되는 외부 데이터를 첨가하거나, 데이터 일반화, Log Scaling 등을 수행합니다. \n",
    "- MinMax, Standard Scaler 등\n",
    "\n",
    "#### <span style=\"color:blue\">3. 독립변수/종속변수 나눈 후  학습 데이터와 평가 데이터로 구분.</span>\n",
    "\n",
    "\n",
    "\n",
    "~~~python\n",
    "\n",
    "X = Data[['col1','col2']] ## 독립 변수\n",
    "y = Data['종속변수']        ## 종속 변수 \n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25, random_state=0)\n",
    "\n",
    "~~~\n",
    "\n",
    "----\n",
    "\n",
    "#### <span style=\"color:blue\">4. 학습 후 성능 확인 </span>\n",
    "#### 각 모델마다 여러 하이퍼파라미터가 존재. 최적화된 파라미터를 구하는 sklearn api 는 두 개 \n",
    "\n",
    "1) `GridSearchCV`\n",
    "\n",
    "~~~python\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "~~~\n",
    "\n",
    "2) `RandomizedSearchCV`\n",
    "\n",
    "~~~python\n",
    "\n",
    "class sklearn.model_selection.RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
    "\n",
    "~~~\n",
    "\n",
    "---\n",
    "\n",
    "~~~python\n",
    "\n",
    "fit(x_train, y_train)     ## 모수 추정(estimate)\n",
    "get_params()              ## 추정된 모수 확인\n",
    "predict(x_test)           ## x_test로부터 라벨 예측\n",
    "predict_log_proba(x_test) ## 로그 취한 확률 예측\n",
    "predict_proba(x_test)     ## 각 라벨로 예측될 확률\n",
    "score(x_test, y_test)     ## 모델 정확도 평가를 위한 mean accuracy\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "**Mean Accuarcy?**  \n",
    "\n",
    "~~~python\n",
    "\n",
    "#분류\n",
    "sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
    "\n",
    "#회귀\n",
    "sklearn.metrics.r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- 이 함수는 모델의 성능을 평가하기 위해 mean accuracy를 제공. 얼마나 맞췄는지 알아보기 위함. \n",
    "- 여러 척도가 존재. \n",
    "\n",
    "### 가장 높은 성능을 갖춘 hyperparameter 을 선택. 이 과정을 <span style=\"color:red\">hyper parameter tuning </span>이라고 함.   \n",
    "\n",
    "####   ->   이것을 가장 좋은 성능을 가진 모델이 나올 때까지 반복. \n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:blue\">6.우리가 최종 선택한 모델과 하이퍼파라미터로 예측하고자 하는 데이터 학습, 결과 얻기 </span>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. 회귀분석\n",
    "\n",
    "- `종속변수와 독립변수 사이의 관계를 가장 잘 설명해주는 하나의 직선`을 구하는 것\n",
    "- y = b0 + b1x + b2x^2 + b3X^3.... 꼴\n",
    "- x는 독립변수..\n",
    "- 이러한 회귀식의 `모수`는 `최소제곱법`을 기준으로 만들어짐. \n",
    "\n",
    "#### 1. `Linear Regression`\n",
    "\n",
    "- 수치형 데이터 => 예측의 문제에서 사용하는 단순선형회귀\n",
    "- ex) 아파트 가격 예측 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dagunoh\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rental_id</th>\n",
       "      <th>rent</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>size_sqft</th>\n",
       "      <th>min_to_subway</th>\n",
       "      <th>floor</th>\n",
       "      <th>building_age_yrs</th>\n",
       "      <th>no_fee</th>\n",
       "      <th>has_roofdeck</th>\n",
       "      <th>has_washer_dryer</th>\n",
       "      <th>has_doorman</th>\n",
       "      <th>has_elevator</th>\n",
       "      <th>has_dishwasher</th>\n",
       "      <th>has_patio</th>\n",
       "      <th>has_gym</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1545</td>\n",
       "      <td>2550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>480</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Upper East Side</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2472</td>\n",
       "      <td>11500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2919</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>916</td>\n",
       "      <td>2</td>\n",
       "      <td>51.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2790</td>\n",
       "      <td>4795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>975</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich Village</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3946</td>\n",
       "      <td>17500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4800</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Soho</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>7582</td>\n",
       "      <td>4210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>532</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>5686</td>\n",
       "      <td>6675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>988</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Tribeca</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>9679</td>\n",
       "      <td>1699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Little Italy</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3537</th>\n",
       "      <td>5188</td>\n",
       "      <td>3475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>651</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Midtown West</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3538</th>\n",
       "      <td>4718</td>\n",
       "      <td>4500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>816</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tribeca</td>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3539 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rental_id   rent  bedrooms  bathrooms  size_sqft  min_to_subway  floor  \\\n",
       "0          1545   2550       0.0          1        480              9    2.0   \n",
       "1          2472  11500       2.0          2       2000              4    1.0   \n",
       "2          2919   4500       1.0          1        916              2   51.0   \n",
       "3          2790   4795       1.0          1        975              3    8.0   \n",
       "4          3946  17500       2.0          2       4800              3    4.0   \n",
       "...         ...    ...       ...        ...        ...            ...    ...   \n",
       "3534       7582   4210       1.0          1        532              3    8.0   \n",
       "3535       5686   6675       2.0          2        988              5   10.0   \n",
       "3536       9679   1699       0.0          1        250              2    5.0   \n",
       "3537       5188   3475       1.0          1        651              6    5.0   \n",
       "3538       4718   4500       1.0          1        816              4   11.0   \n",
       "\n",
       "      building_age_yrs  no_fee  has_roofdeck  has_washer_dryer  has_doorman  \\\n",
       "0                   17       1             1                 0            0   \n",
       "1                   96       0             0                 0            0   \n",
       "2                   29       0             1                 0            1   \n",
       "3                   31       0             0                 0            1   \n",
       "4                  136       0             0                 0            1   \n",
       "...                ...     ...           ...               ...          ...   \n",
       "3534                16       1             1                 1            1   \n",
       "3535                 9       1             1                 1            1   \n",
       "3536                96       0             0                 0            0   \n",
       "3537                14       1             0                 1            1   \n",
       "3538                 9       0             1                 1            1   \n",
       "\n",
       "      has_elevator  has_dishwasher  has_patio  has_gym       neighborhood  \\\n",
       "0                1               1          0        1    Upper East Side   \n",
       "1                0               0          0        0  Greenwich Village   \n",
       "2                1               1          0        0            Midtown   \n",
       "3                1               1          0        1  Greenwich Village   \n",
       "4                1               1          0        1               Soho   \n",
       "...            ...             ...        ...      ...                ...   \n",
       "3534             1               1          0        1            Chelsea   \n",
       "3535             1               1          0        1            Tribeca   \n",
       "3536             0               0          0        0       Little Italy   \n",
       "3537             1               1          0        1       Midtown West   \n",
       "3538             1               0          1        1            Tribeca   \n",
       "\n",
       "        borough  \n",
       "0     Manhattan  \n",
       "1     Manhattan  \n",
       "2     Manhattan  \n",
       "3     Manhattan  \n",
       "4     Manhattan  \n",
       "...         ...  \n",
       "3534  Manhattan  \n",
       "3535  Manhattan  \n",
       "3536  Manhattan  \n",
       "3537  Manhattan  \n",
       "3538  Manhattan  \n",
       "\n",
       "[3539 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#다중선형회귀 실습 \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"Desktop/21Work/datasets/streeteasy/manhattan.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rental_id', 'rent', 'bedrooms', 'bathrooms', 'size_sqft',\n",
       "       'min_to_subway', 'floor', 'building_age_yrs', 'no_fee', 'has_roofdeck',\n",
       "       'has_washer_dryer', 'has_doorman', 'has_elevator', 'has_dishwasher',\n",
       "       'has_patio', 'has_gym', 'neighborhood', 'borough'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n",
    "\n",
    "#rent: 주택의 임대료\n",
    "#그 외의 항목들은 침실이 몇 개 있는지, 엘레베이터가 있는지, 식기세척기가 있는지 등 주택에 대한 다양한 정보. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data[['bedrooms', 'bathrooms', 'size_sqft', 'min_to_subway', 'floor', 'building_age_yrs', 'no_fee', 'has_roofdeck', 'has_washer_dryer', 'has_doorman', 'has_elevator', 'has_dishwasher', 'has_patio', 'has_gym']]\n",
    "y = data[['rent']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, test_size=0.2)\n",
    "\n",
    "#선형회귀 모형에 학습\n",
    "\n",
    "mlr = LinearRegression()\n",
    "mlr.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4815.02754017],\n",
       "       [ 3324.16722412],\n",
       "       [ 3226.88188658],\n",
       "       [ 5319.27506338],\n",
       "       [13779.18088406],\n",
       "       [ 5558.19418411],\n",
       "       [ 6417.74720611],\n",
       "       [ 4332.85707469],\n",
       "       [ 1950.0301566 ],\n",
       "       [ 3582.04194743]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#예측값 \n",
    "y_predict = mlr.predict(x_test)\n",
    "y_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7834128907373274\n"
     ]
    }
   ],
   "source": [
    "#이 선형회귀 모델의 성능\n",
    "\n",
    "print(mlr.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프로 그려보기 \n",
    "\n",
    "plt.scatter(y_test, y_predict, alpha=0.4)\n",
    "plt.xlabel(\"Actual Rent\")\n",
    "plt.ylabel(\"Predicted Rent\")\n",
    "plt.title(\"MULTIPLE LINEAR REGRESSION\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 2. `Logistic Regression`\n",
    "\n",
    "- 데이터가 **어떤 범주에 속할 확률을 0에서 1 사이의 값으로 예측**하고 \n",
    "그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘\n",
    "\n",
    "- 범주형 자료 => 분류 문제에서 사용하는 로지스틱회귀. \n",
    "- ex) A 라벨과 B 라벨 분류하기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종양 반응 : ['malignant' 'benign']\n",
      "target : [malignant:악성, benign: 양성]\n",
      "데이터 수 : 569\n",
      "데이터 열 이름 : ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "data 예시 :  [1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    breast_cancer = datasets.load_breast_cancer()\n",
    "    print('종양 반응 :', breast_cancer.target_names)\n",
    "    print('target : [malignant:악성, benign: 양성]')\n",
    "    print('데이터 수 :', len(breast_cancer.data))\n",
    "    print('데이터 열 이름 :', breast_cancer.feature_names)\n",
    "    print('data 예시 : ', breast_cancer.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>isCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  isCancer  \n",
       "0          0.4601                  0.11890         0  \n",
       "1          0.2750                  0.08902         0  \n",
       "2          0.3613                  0.08758         0  \n",
       "3          0.6638                  0.17300         0  \n",
       "4          0.2364                  0.07678         0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 정렬 \n",
    "\n",
    "data2= pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "sy = pd.Series(breast_cancer.target, dtype='category')\n",
    "data2['isCancer'] = sy\n",
    "\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n",
      "(426,) (143,)\n"
     ]
    }
   ],
   "source": [
    "#독립변수, 종속변수 구분\n",
    "x = data2.loc[:, 'mean radius':'worst fractal dimension']\n",
    "y = data2['isCancer']\n",
    "\n",
    "#train, test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dagunoh/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 0 1 0 1 0 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1\n",
      " 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 0 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#x_test 넣었을 때 결과가 어떻게 되는지. \n",
    "#이 친구가 y_test랑 비슷할 수록 성능이 좋은 것. \n",
    "\n",
    "y_pred = lg.predict(x_test)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "print('정확도 :', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. 의사결정나무 (Decision Tree), RandomForest\n",
    "\n",
    "- 분류, 회귀 모두에게 쓰임\n",
    "\n",
    "- 훈련 과정에 구성한 다수의 결정 트리를 이용해 분류하거나, 평균 예측치를 출력함으로써 동작\n",
    "\n",
    "- 꽤 정확하고, 여러개의 입력 변수들을 다루는 것 가능. \n",
    "\n",
    "**왜 정확할까?**\n",
    "\n",
    "종속변수가 30개라 치면, 30개의 가지를 만들어서 분류해야하기 때문에 너무 많은 가지가 만들어질 것 -> 오버피팅. 하지만 랜덤으로 몇개의 종속변수만 설정해서 하나의 결정트리를 만들고, 또 이런식으로 계속 전개하면서 예측값들 중 가장 많이 나온 값을 최종 예측값으로 정하는 것. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>isCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  isCancer  \n",
       "0                  0.2654          0.4601                  0.11890         0  \n",
       "1                  0.1860          0.2750                  0.08902         0  \n",
       "2                  0.2430          0.3613                  0.08758         0  \n",
       "3                  0.2575          0.6638                  0.17300         0  \n",
       "4                  0.1625          0.2364                  0.07678         0  \n",
       "..                    ...             ...                      ...       ...  \n",
       "564                0.2216          0.2060                  0.07115         0  \n",
       "565                0.1628          0.2572                  0.06637         0  \n",
       "566                0.1418          0.2218                  0.07820         0  \n",
       "567                0.2650          0.4087                  0.12400         0  \n",
       "568                0.0000          0.2871                  0.07039         1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data2 #위의 Logistic regression에서 사용한 데이터 그대로 사용. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 30) (143, 30)\n",
      "(426,) (143,)\n"
     ]
    }
   ],
   "source": [
    "x = data2.loc[:, 'mean radius':'worst fractal dimension']\n",
    "y = data2['isCancer']\n",
    "\n",
    "#train, test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:  {'max_depth': 6, 'min_samples_leaf': 8, 'min_samples_split': 20, 'n_estimators': 14}\n",
      "최고 예측 정확도: 0.9507\n",
      "cross_val_score:  [0.94186047 0.95294118 0.91764706 0.94117647 0.97647059]\n"
     ]
    }
   ],
   "source": [
    "#하이퍼파라미터 튜닝\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [10, 11, 12, 13, 14,15,16,17,18,19, 20],\n",
    "           'max_depth' : [6, 8, 10, 12, 15, 18,],\n",
    "           'min_samples_leaf' : [8, 12, 18],\n",
    "           'min_samples_split' : [8, 16, 20]\n",
    "            }\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = 0, n_jobs = -1)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 3, n_jobs = -1)\n",
    "grid_cv.fit(x_train, y_train)\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))\n",
    "print('cross_val_score: ', cross_val_score(rf_clf,x_train,y_train,cv=kf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth= 6, min_samples_leaf =  8, min_samples_split =  20, n_estimators= 14)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    " \n",
    "# 예측\n",
    "y_pred = rf.predict(x_test)\n",
    " \n",
    "# 정확도 확인\n",
    "print('정확도 :', metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9443349753694582"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cross_val_score(rf_clf,x_test,y_test,cv=kf)\n",
    "sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. SVM (support vector machine) \n",
    "\n",
    "- 주어진 데이터가 어느 카테고리에 속할지 판단. \n",
    "- Margin 최대화 하는 방향으로 => 이상치의 영향을 많이 받지 않음. \n",
    "- 비선형 분류에서도 사용 가능. \n",
    "\n",
    "- **parameter** : **gamma** = Gamma가 크면 decision boundary는 더 굴곡지고, Gamma가 작으면 decision boundary는 직선에 가까움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>isCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  isCancer  \n",
       "0                  0.2654          0.4601                  0.11890         0  \n",
       "1                  0.1860          0.2750                  0.08902         0  \n",
       "2                  0.2430          0.3613                  0.08758         0  \n",
       "3                  0.2575          0.6638                  0.17300         0  \n",
       "4                  0.1625          0.2364                  0.07678         0  \n",
       "..                    ...             ...                      ...       ...  \n",
       "564                0.2216          0.2060                  0.07115         0  \n",
       "565                0.1628          0.2572                  0.06637         0  \n",
       "566                0.1418          0.2218                  0.07820         0  \n",
       "567                0.2650          0.4087                  0.12400         0  \n",
       "568                0.0000          0.2871                  0.07039         1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도 : 0.9370629370629371\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "y_pred_svc = svm.predict(x_test)\n",
    "\n",
    "# 정확도 확인\n",
    "print('정확도 :', metrics.accuracy_score(y_test, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## `오늘의 실습`\n",
    "### [IDMB 영화 리뷰 감성분석]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dagunoh\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"It must be assumed that those who praised thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
       "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
       "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data3 = pd.read_csv('Desktop/Git/2021_Work/2021/text_analysis/labeledTrainData.tsv', header=0, sep='\\t', quoting=3)\n",
    "data3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"With all this stuff going down at the moment with MJ i\\'ve started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ\\'s feeling towards the press and also the obvious message of drugs are bad m\\'kay.<br /><br />Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.<br /><br />The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci\\'s character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ\\'s music.<br /><br />Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.<br /><br />Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ\\'s bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i\\'ve gave this subject....hmmm well i don\\'t know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\"'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#데이터 전처리 : html 태그 여전히 존재, 숫자 제거 등\n",
    "\n",
    "data3['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer #어간 추출\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "data3['review'] = data3['review'].str.replace('<br />',' ')\n",
    "data3['review'] = data3['review'].apply( lambda x : re.sub(\"[^a-zA-Z]\",' ',x))\n",
    "data3['review'] = data3['review'].str.lower()\n",
    "\n",
    "\n",
    "##불용어 제거\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data3['review'] = data3['review'].apply(lambda x: ' '.join(word for word \n",
    "                                             in x.split() if word not in stop_words))\n",
    "    \n",
    "##어간만!              \n",
    "ps = PorterStemmer()\n",
    "data3['review'] = data3['review'].apply(lambda x: ' '.join(ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff go moment mj start listen music watch od...\n",
       "1        classic war world timothi hine entertain film ...\n",
       "2        film start manag nichola bell give welcom inve...\n",
       "3        must assum prais film greatest film opera ever...\n",
       "4        superbl trashi wondrous unpretenti exploit hoo...\n",
       "                               ...                        \n",
       "24995    seem like consider gone imdb review film went ...\n",
       "24996    believ made film complet unnecessari first fil...\n",
       "24997    guy loser get girl need build pick stronger su...\n",
       "24998    minut documentari bu uel made earli one spain ...\n",
       "24999    saw movi child broke heart stori unfinish end ...\n",
       "Name: review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17500,), (7500,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data3['review']\n",
    "y = data3['sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.3, random_state=156)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1692     girlfriend stun bad film minut would call quit...\n",
       "13392    expect script begin therefor noth director wor...\n",
       "21063    german film someth women come castl beyond rea...\n",
       "10335    richard tyler littl boy scare everyth like rid...\n",
       "16847    run group stop comedian exploit spent past mon...\n",
       "                               ...                        \n",
       "14848    like comment film script arriv halfway movi on...\n",
       "8450     first let say notori absolut charm film loving...\n",
       "8221     realist movi sure except fact charact look lik...\n",
       "10638    spend day dedic ron howard swear work entir un...\n",
       "20673    jerri spi tom listen creepi stori radio seiz o...\n",
       "Name: review, Length: 7500, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cnt_vect', CountVectorizer(ngram_range=(1,2))),\n",
    "    ('lr_clf', LogisticRegression(C=10))])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "pred = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도는 0.8831\n"
     ]
    }
   ],
   "source": [
    "print('예측 정확도는 {0:.4f}'.format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
